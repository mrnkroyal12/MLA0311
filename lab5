import numpy as np
GRID_SIZE = 5
PICKUP = (4, 4)
ACTIONS = {
    'U': (-1, 0),
    'D': (1, 0),
    'L': (0, -1),
    'R': (0, 1)
}

gamma = 0.9
theta = 0.001
V = np.zeros((GRID_SIZE, GRID_SIZE))

def is_valid(x, y):
    return 0 <= x < GRID_SIZE and 0 <= y < GRID_SIZE

def reward(state):
    return 10 if state == PICKUP else -1
while True:
    delta = 0
    new_V = np.copy(V)

    for i in range(GRID_SIZE):
        for j in range(GRID_SIZE):
            if (i, j) == PICKUP:
                continue

            action_values = []
            for dx, dy in ACTIONS.values():
                ni, nj = i + dx, j + dy
                if is_valid(ni, nj):
                    action_values.append(
                        reward((ni, nj)) + gamma * V[ni][nj]
                    )
                else:
                    action_values.append(
                        reward((i, j)) + gamma * V[i][j]
                    )

            new_V[i][j] = max(action_values)
            delta = max(delta, abs(new_V[i][j] - V[i][j]))

    V = new_V
    if delta < theta:
        break
policy = np.full((GRID_SIZE, GRID_SIZE), ' ')

for i in range(GRID_SIZE):
    for j in range(GRID_SIZE):
        if (i, j) == PICKUP:
            policy[i][j] = 'P'
            continue

        best_action = None
        best_value = -float('inf')

        for action, (dx, dy) in ACTIONS.items():
            ni, nj = i + dx, j + dy
            if is_valid(ni, nj):
                value = reward((ni, nj)) + gamma * V[ni][nj]
                if value > best_value:
                    best_value = value
                    best_action = action

        policy[i][j] = best_action

print("Optimal Value Function:")
print(V)

print("\nOptimal Dispatch Policy:")
print(policy)
